{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joanadecaa1/data_processing/blob/main/spark/challenges/challenge_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# CHALLENGE 1\n",
        "##  Implement INGESTION process\n",
        "- Set up path in the \"lake\"\n",
        "  - !mkdir -p /content/lake/bronze\n",
        "\n",
        "- Read data from API https://api.carrismetropolitana.pt/\n",
        "  - Endpoints:\n",
        "    - vehicles\n",
        "    - lines\n",
        "    - municipalities\n",
        "  - Use StructFields to enforce schema\n",
        "\n",
        "- Transformations\n",
        "  - vehicles\n",
        "    - create \"date\" extracted from \"timestamp\" column (format: date - yyyy-mm-dd or yyyymmdd)\n",
        "\n",
        "- Write data as PARQUET into the BRONZE layer (/content/lake/bronze)\n",
        "  - Partition \"vehicles\" by \"date\" column\n",
        "  - Paths:\n",
        "    - vehicles - path: /content/lake/bronze/vehicles\n",
        "    - lines - path: /content/lake/bronze/lines\n",
        "    - municipalities - path: /content/lake/bronze/municipalities\n",
        "  - Make sure there is only 1 single parquet created\n",
        "  - Use overwrite as write mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "c410e46c-4a50-43aa-926f-d0417c6280d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import requests\n",
        "\n",
        "class ETLFlow:\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def extract_from_file(self, format: str, path: str, **kwargs) -> DataFrame:\n",
        "        df = self.spark.read.format(format).load(path)\n",
        "        print(f\"Extracted data from {path}:\")\n",
        "        df.show(5, truncate=False)  # Display the first 5 rows for inspection\n",
        "        return df\n",
        "\n",
        "    def extract_from_api(self, url: str, schema: StructType = None):\n",
        "        response = requests.get(url)\n",
        "        rdd = self.spark.sparkContext.parallelize(response.json())\n",
        "        if schema:\n",
        "            df = self.spark.read.schema(schema).json(rdd)\n",
        "        else:\n",
        "            df = self.spark.read.json(rdd)\n",
        "        print(f\"Extracted data from API {url}:\")\n",
        "        df.show(5, truncate=False)  # Display the first 5 rows for inspection\n",
        "        return df\n",
        "\n",
        "    def load(self, df: DataFrame, format: str, path: str, partition_column: str = None, **kwargs) -> None:\n",
        "        print(f\"Loading data to {path}...\")\n",
        "        if partition_column:\n",
        "            df.coalesce(1).write.mode(\"overwrite\").partitionBy(partition_column).format(format).save(path)\n",
        "        else:\n",
        "            df.coalesce(1).write.mode(\"overwrite\").format(format).save(path)\n",
        "        print(f\"Data successfully loaded to {path}\")\n",
        "\n",
        "class ETLTask(ETLFlow):\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        super().__init__(spark)\n",
        "\n",
        "    def ingestion_lines(self):\n",
        "        # Define schema for lines\n",
        "        lines_schema = StructType([\n",
        "            StructField('color', StringType(), True),\n",
        "            StructField('facilities', ArrayType(StringType(), True), True),\n",
        "            StructField('id', StringType(), True),\n",
        "            StructField('localities', ArrayType(StringType(), True), True),\n",
        "            StructField('long_name', StringType(), True),\n",
        "            StructField('municipalities', ArrayType(StringType(), True), True),\n",
        "            StructField('patterns', ArrayType(StringType(), True), True),\n",
        "            StructField('routes', ArrayType(StringType(), True), True),\n",
        "            StructField('short_name', StringType(), True),\n",
        "            StructField('text_color', StringType(), True)\n",
        "        ])\n",
        "        # Ingest data\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/lines\", schema=lines_schema)\n",
        "        # Load into Bronze layer\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/lines\")\n",
        "\n",
        "    def ingestion_vehicles(self):\n",
        "        # Define schema for vehicles\n",
        "        vehicle_schema = StructType([\n",
        "            StructField('bearing', IntegerType(), True),\n",
        "            StructField('block_id', StringType(), True),\n",
        "            StructField('current_status', StringType(), True),\n",
        "            StructField('id', StringType(), True),\n",
        "            StructField('lat', FloatType(), True),\n",
        "            StructField('line_id', StringType(), True),\n",
        "            StructField('lon', FloatType(), True),\n",
        "            StructField('pattern_id', StringType(), True),\n",
        "            StructField('route_id', StringType(), True),\n",
        "            StructField('schedule_relationship', StringType(), True),\n",
        "            StructField('shift_id', StringType(), True),\n",
        "            StructField('speed', FloatType(), True),\n",
        "            StructField('stop_id', StringType(), True),\n",
        "            StructField('timestamp', TimestampType(), True),\n",
        "            StructField('trip_id', StringType(), True)\n",
        "        ])\n",
        "        # Ingest data\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/vehicles\", schema=vehicle_schema)\n",
        "        print(\"Raw data from API - Vehicles:\")\n",
        "        df.show(5, truncate=False)  # Display the first 5 rows of raw data\n",
        "\n",
        "        # Add date column\n",
        "        df = df.withColumn(\"date\", expr(\"date(timestamp)\"))\n",
        "        print(\"Data after adding date column:\")\n",
        "        df.show(5, truncate=False)  # Display data after adding date column\n",
        "\n",
        "        # Load into Bronze layer, partitioned by date\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/vehicles\", partition_column=\"date\")\n",
        "\n",
        "    def ingestion_municipalities(self):\n",
        "        # Define schema for municipalities (updated)\n",
        "        municipalities_schema = StructType([\n",
        "            StructField('id', StringType(), True),\n",
        "            StructField('name', StringType(), True),\n",
        "            StructField('district_id', StringType(), True),  # Renamed to match API response\n",
        "            StructField('district_name', StringType(), True),  # New field added\n",
        "            StructField('prefix', StringType(), True),\n",
        "            StructField('region_id', StringType(), True),\n",
        "            StructField('region_name', StringType(), True)\n",
        "        ])\n",
        "        # Ingest data\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/municipalities\", schema=municipalities_schema)\n",
        "        print(\"Raw data from API - Municipalities:\")\n",
        "        df.show(5, truncate=False)  # Display the first 5 rows of raw data\n",
        "\n",
        "        # Add ingestion date\n",
        "        df = df.withColumn(\"ingestion_date\", current_date())\n",
        "        print(\"Data after adding ingestion date:\")\n",
        "        df.show(5, truncate=False)  # Display data after adding ingestion date\n",
        "\n",
        "        # Load into Bronze layer\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/municipalities\")\n",
        "\n",
        "    def cleansing_vehicles(self):\n",
        "        # Read raw data\n",
        "        df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/vehicles\")\n",
        "        print(\"Raw data from Bronze - Vehicles:\")\n",
        "        df.show(5, truncate=False)  # Display the first 5 rows of raw data\n",
        "\n",
        "        # Transformations\n",
        "        df = df.withColumn(\"new_column\", lit(\"test\"))\n",
        "        print(\"Data after adding new column:\")\n",
        "        df.show(5, truncate=False)  # Display data after adding new column\n",
        "\n",
        "        df = df.drop_duplicates()\n",
        "        print(\"Data after removing duplicates:\")\n",
        "        df.show(5, truncate=False)  # Display data after removing duplicates\n",
        "\n",
        "        # Load into Silver layer\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/vehicles\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Initialize SparkSession\n",
        "    spark = SparkSession.builder.master('local').appName('ETL Program').getOrCreate()\n",
        "    print(\"Starting ETL program\")\n",
        "    etl = ETLTask(spark)\n",
        "\n",
        "    # Run tasks\n",
        "    print(\"Running Task - Ingestion Vehicles\")\n",
        "    etl.ingestion_vehicles()\n",
        "\n",
        "    print(\"Running Task - Ingestion Lines\")\n",
        "    etl.ingestion_lines()\n",
        "\n",
        "    print(\"Running Task - Ingestion Municipalities\")\n",
        "    etl.ingestion_municipalities()\n",
        "\n",
        "    print(\"Running Task - Cleansing Vehicles\")\n",
        "    etl.cleansing_vehicles()\n",
        "\n",
        "    print(\"ETL program completed\")\n"
      ],
      "metadata": {
        "id": "7P39vFz_0bwl",
        "outputId": "865c67a6-2ae5-4e0a-c845-778c472460f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ETL program\n",
            "Running Task - Ingestion Vehicles\n",
            "Extracted data from API https://api.carrismetropolitana.pt/vehicles:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+\n",
            "|348    |20241126-64010339-112550234560|IN_TRANSIT_TO |44|12061|38.5271  |4422   |-8.902385|4422_1_1  |4422_1  |SCHEDULED            |112550234560|0.0      |160438 |2024-11-26 23:33:49|4422_1_1|2600|2315_24UH5    |\n",
            "|52     |20241126-64010050-121930234560|INCOMING_AT   |44|12514|38.69575 |4600   |-8.946908|4600_0_1  |4600_0  |SCHEDULED            |121930234560|12.777778|100153 |2024-11-26 23:34:01|4600_0_1|2600|2300_24UH5    |\n",
            "|313    |1_1437-11                     |INCOMING_AT   |41|1114 |38.72802 |1101   |-9.217793|1101_0_2  |1101_0  |SCHEDULED            |1498        |8.611111 |120001 |2024-11-26 23:32:58|1101_0_2_2230_2259_0_1_1V0AN|\n",
            "|150    |20241126-64010048-121950234560|INCOMING_AT   |44|12537|38.65782 |4611   |-8.992207|4611_0_2  |4611_0  |SCHEDULED            |121950234560|9.722222 |090059 |2024-11-26 23:34:00|4611_0_2|2600|2330_24UH5    |\n",
            "|58     |20241126-64010185-112630234560|IN_TRANSIT_TO |44|12734|38.521942|4440   |-8.899272|4440_0_2  |4440_0  |SCHEDULED            |112630234560|9.444445 |160159 |2024-11-26 23:33:49|4440_0_2|2600|2330_24UH5    |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Raw data from API - Vehicles:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+\n",
            "|348    |20241126-64010339-112550234560|IN_TRANSIT_TO |44|12061|38.5271  |4422   |-8.902385|4422_1_1  |4422_1  |SCHEDULED            |112550234560|0.0      |160438 |2024-11-26 23:33:49|4422_1_1|2600|2315_24UH5    |\n",
            "|52     |20241126-64010050-121930234560|INCOMING_AT   |44|12514|38.69575 |4600   |-8.946908|4600_0_1  |4600_0  |SCHEDULED            |121930234560|12.777778|100153 |2024-11-26 23:34:01|4600_0_1|2600|2300_24UH5    |\n",
            "|313    |1_1437-11                     |INCOMING_AT   |41|1114 |38.72802 |1101   |-9.217793|1101_0_2  |1101_0  |SCHEDULED            |1498        |8.611111 |120001 |2024-11-26 23:32:58|1101_0_2_2230_2259_0_1_1V0AN|\n",
            "|150    |20241126-64010048-121950234560|INCOMING_AT   |44|12537|38.65782 |4611   |-8.992207|4611_0_2  |4611_0  |SCHEDULED            |121950234560|9.722222 |090059 |2024-11-26 23:34:00|4611_0_2|2600|2330_24UH5    |\n",
            "|58     |20241126-64010185-112630234560|IN_TRANSIT_TO |44|12734|38.521942|4440   |-8.899272|4440_0_2  |4440_0  |SCHEDULED            |112630234560|9.444445 |160159 |2024-11-26 23:33:49|4440_0_2|2600|2330_24UH5    |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Data after adding date column:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |date      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "|348    |20241126-64010339-112550234560|IN_TRANSIT_TO |44|12061|38.5271  |4422   |-8.902385|4422_1_1  |4422_1  |SCHEDULED            |112550234560|0.0      |160438 |2024-11-26 23:33:49|4422_1_1|2600|2315_24UH5    |2024-11-26|\n",
            "|52     |20241126-64010050-121930234560|INCOMING_AT   |44|12514|38.69575 |4600   |-8.946908|4600_0_1  |4600_0  |SCHEDULED            |121930234560|12.777778|100153 |2024-11-26 23:34:01|4600_0_1|2600|2300_24UH5    |2024-11-26|\n",
            "|313    |1_1437-11                     |INCOMING_AT   |41|1114 |38.72802 |1101   |-9.217793|1101_0_2  |1101_0  |SCHEDULED            |1498        |8.611111 |120001 |2024-11-26 23:32:58|1101_0_2_2230_2259_0_1_1V0AN|2024-11-26|\n",
            "|150    |20241126-64010048-121950234560|INCOMING_AT   |44|12537|38.65782 |4611   |-8.992207|4611_0_2  |4611_0  |SCHEDULED            |121950234560|9.722222 |090059 |2024-11-26 23:34:00|4611_0_2|2600|2330_24UH5    |2024-11-26|\n",
            "|58     |20241126-64010185-112630234560|IN_TRANSIT_TO |44|12734|38.521942|4440   |-8.899272|4440_0_2  |4440_0  |SCHEDULED            |112630234560|9.444445 |160159 |2024-11-26 23:33:49|4440_0_2|2600|2330_24UH5    |2024-11-26|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Loading data to /content/lake/bronze/vehicles...\n",
            "Data successfully loaded to /content/lake/bronze/vehicles\n",
            "Running Task - Ingestion Lines\n",
            "Extracted data from API https://api.carrismetropolitana.pt/lines:\n",
            "+-------+----------+----+----------------------------------------+----------------------------------------------------------------------------------------+--------------+----------------------------------------+------------------------+----------+----------+\n",
            "|color  |facilities|id  |localities                              |long_name                                                                               |municipalities|patterns                                |routes                  |short_name|text_color|\n",
            "+-------+----------+----+----------------------------------------+----------------------------------------------------------------------------------------+--------------+----------------------------------------+------------------------+----------+----------+\n",
            "|#C61D23|[]        |1001|[Alfragide, Amadora, Reboleira, Buraca] |Alfragide (Estr Seminario) - Reboleira (Estação)                                        |[1115]        |[1001_0_1, 1001_0_2]                    |[1001_0]                |1001      |#FFFFFF   |\n",
            "|#C61D23|[]        |1002|[Reboleira, Amadora, Atalaia, Alfragide]|Reboleira (Estação) | Circular via Alfragide (Centro comercial ) e Amadora (Estação Sul)|[1115]        |[1002_0_3]                              |[1002_0]                |1002      |#FFFFFF   |\n",
            "|#C61D23|[]        |1003|[Amadora, Amadora Este]                 |Amadora (Estação Norte) - Amadora Este (Metro)                                          |[1115]        |[1003_0_1, 1003_0_2]                    |[1003_0]                |1003      |#FFFFFF   |\n",
            "|#C61D23|[]        |1004|[Amadora, Moinhos da Funcheira]         |Amadora (Estação Norte) via Moinhos da Funcheira | Circular                             |[1115]        |[1004_0_3]                              |[1004_0]                |1004      |#FFFFFF   |\n",
            "|#C61D23|[]        |1005|[Amadora, Casal da Mira]                |Amadora (Estação Norte) - UBBO                                                          |[1115]        |[1005_0_1, 1005_0_2, 1005_1_2, 1005_2_3]|[1005_0, 1005_1, 1005_2]|1005      |#FFFFFF   |\n",
            "+-------+----------+----+----------------------------------------+----------------------------------------------------------------------------------------+--------------+----------------------------------------+------------------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Loading data to /content/lake/bronze/lines...\n",
            "Data successfully loaded to /content/lake/bronze/lines\n",
            "Running Task - Ingestion Municipalities\n",
            "Extracted data from API https://api.carrismetropolitana.pt/municipalities:\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+\n",
            "|id  |name             |district_id|district_name|prefix|region_id|region_name     |\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+\n",
            "|0712|Vendas Novas     |07         |Évora        |19    |PT187    |Alentejo Central|\n",
            "|1101|Alenquer         |11         |Lisboa       |20    |PT16B    |Oeste           |\n",
            "|1102|Arruda dos Vinhos|11         |Lisboa       |20    |PT16B    |Oeste           |\n",
            "|1105|Cascais          |11         |Lisboa       |05    |PT170    |AML             |\n",
            "|1106|Lisboa           |11         |Lisboa       |06    |PT170    |AML             |\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Raw data from API - Municipalities:\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+\n",
            "|id  |name             |district_id|district_name|prefix|region_id|region_name     |\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+\n",
            "|0712|Vendas Novas     |07         |Évora        |19    |PT187    |Alentejo Central|\n",
            "|1101|Alenquer         |11         |Lisboa       |20    |PT16B    |Oeste           |\n",
            "|1102|Arruda dos Vinhos|11         |Lisboa       |20    |PT16B    |Oeste           |\n",
            "|1105|Cascais          |11         |Lisboa       |05    |PT170    |AML             |\n",
            "|1106|Lisboa           |11         |Lisboa       |06    |PT170    |AML             |\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Data after adding ingestion date:\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+--------------+\n",
            "|id  |name             |district_id|district_name|prefix|region_id|region_name     |ingestion_date|\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+--------------+\n",
            "|0712|Vendas Novas     |07         |Évora        |19    |PT187    |Alentejo Central|2024-11-26    |\n",
            "|1101|Alenquer         |11         |Lisboa       |20    |PT16B    |Oeste           |2024-11-26    |\n",
            "|1102|Arruda dos Vinhos|11         |Lisboa       |20    |PT16B    |Oeste           |2024-11-26    |\n",
            "|1105|Cascais          |11         |Lisboa       |05    |PT170    |AML             |2024-11-26    |\n",
            "|1106|Lisboa           |11         |Lisboa       |06    |PT170    |AML             |2024-11-26    |\n",
            "+----+-----------------+-----------+-------------+------+---------+----------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Loading data to /content/lake/bronze/municipalities...\n",
            "Data successfully loaded to /content/lake/bronze/municipalities\n",
            "Running Task - Cleansing Vehicles\n",
            "Extracted data from /content/lake/bronze/vehicles:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |date      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "|348    |20241126-64010339-112550234560|IN_TRANSIT_TO |44|12061|38.5271  |4422   |-8.902385|4422_1_1  |4422_1  |SCHEDULED            |112550234560|0.0      |160438 |2024-11-26 23:33:49|4422_1_1|2600|2315_24UH5    |2024-11-26|\n",
            "|52     |20241126-64010050-121930234560|INCOMING_AT   |44|12514|38.69575 |4600   |-8.946908|4600_0_1  |4600_0  |SCHEDULED            |121930234560|12.777778|100153 |2024-11-26 23:34:01|4600_0_1|2600|2300_24UH5    |2024-11-26|\n",
            "|313    |1_1437-11                     |INCOMING_AT   |41|1114 |38.72802 |1101   |-9.217793|1101_0_2  |1101_0  |SCHEDULED            |1498        |8.611111 |120001 |2024-11-26 23:32:58|1101_0_2_2230_2259_0_1_1V0AN|2024-11-26|\n",
            "|150    |20241126-64010048-121950234560|INCOMING_AT   |44|12537|38.65782 |4611   |-8.992207|4611_0_2  |4611_0  |SCHEDULED            |121950234560|9.722222 |090059 |2024-11-26 23:34:00|4611_0_2|2600|2330_24UH5    |2024-11-26|\n",
            "|58     |20241126-64010185-112630234560|IN_TRANSIT_TO |44|12734|38.521942|4440   |-8.899272|4440_0_2  |4440_0  |SCHEDULED            |112630234560|9.444445 |160159 |2024-11-26 23:33:49|4440_0_2|2600|2330_24UH5    |2024-11-26|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Raw data from Bronze - Vehicles:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |date      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "|348    |20241126-64010339-112550234560|IN_TRANSIT_TO |44|12061|38.5271  |4422   |-8.902385|4422_1_1  |4422_1  |SCHEDULED            |112550234560|0.0      |160438 |2024-11-26 23:33:49|4422_1_1|2600|2315_24UH5    |2024-11-26|\n",
            "|52     |20241126-64010050-121930234560|INCOMING_AT   |44|12514|38.69575 |4600   |-8.946908|4600_0_1  |4600_0  |SCHEDULED            |121930234560|12.777778|100153 |2024-11-26 23:34:01|4600_0_1|2600|2300_24UH5    |2024-11-26|\n",
            "|313    |1_1437-11                     |INCOMING_AT   |41|1114 |38.72802 |1101   |-9.217793|1101_0_2  |1101_0  |SCHEDULED            |1498        |8.611111 |120001 |2024-11-26 23:32:58|1101_0_2_2230_2259_0_1_1V0AN|2024-11-26|\n",
            "|150    |20241126-64010048-121950234560|INCOMING_AT   |44|12537|38.65782 |4611   |-8.992207|4611_0_2  |4611_0  |SCHEDULED            |121950234560|9.722222 |090059 |2024-11-26 23:34:00|4611_0_2|2600|2330_24UH5    |2024-11-26|\n",
            "|58     |20241126-64010185-112630234560|IN_TRANSIT_TO |44|12734|38.521942|4440   |-8.899272|4440_0_2  |4440_0  |SCHEDULED            |112630234560|9.444445 |160159 |2024-11-26 23:33:49|4440_0_2|2600|2330_24UH5    |2024-11-26|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Data after adding new column:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+----------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |date      |new_column|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+----------+\n",
            "|348    |20241126-64010339-112550234560|IN_TRANSIT_TO |44|12061|38.5271  |4422   |-8.902385|4422_1_1  |4422_1  |SCHEDULED            |112550234560|0.0      |160438 |2024-11-26 23:33:49|4422_1_1|2600|2315_24UH5    |2024-11-26|test      |\n",
            "|52     |20241126-64010050-121930234560|INCOMING_AT   |44|12514|38.69575 |4600   |-8.946908|4600_0_1  |4600_0  |SCHEDULED            |121930234560|12.777778|100153 |2024-11-26 23:34:01|4600_0_1|2600|2300_24UH5    |2024-11-26|test      |\n",
            "|313    |1_1437-11                     |INCOMING_AT   |41|1114 |38.72802 |1101   |-9.217793|1101_0_2  |1101_0  |SCHEDULED            |1498        |8.611111 |120001 |2024-11-26 23:32:58|1101_0_2_2230_2259_0_1_1V0AN|2024-11-26|test      |\n",
            "|150    |20241126-64010048-121950234560|INCOMING_AT   |44|12537|38.65782 |4611   |-8.992207|4611_0_2  |4611_0  |SCHEDULED            |121950234560|9.722222 |090059 |2024-11-26 23:34:00|4611_0_2|2600|2330_24UH5    |2024-11-26|test      |\n",
            "|58     |20241126-64010185-112630234560|IN_TRANSIT_TO |44|12734|38.521942|4440   |-8.899272|4440_0_2  |4440_0  |SCHEDULED            |112630234560|9.444445 |160159 |2024-11-26 23:33:49|4440_0_2|2600|2330_24UH5    |2024-11-26|test      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Data after removing duplicates:\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+----------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon      |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                     |date      |new_column|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+----------+\n",
            "|155    |1068-11                       |INCOMING_AT   |42|2339 |38.77738 |2711   |-9.103251|2711_0_1  |2711_0  |SCHEDULED            |1205        |10.555555|070611 |2024-11-26 23:33:49|2711_0_1|1|1|2300_GY0RX     |2024-11-26|test      |\n",
            "|0      |1537-11                       |STOPPED_AT    |42|2209 |38.79574 |2523   |-9.179373|2523_0_1  |2523_0  |SCHEDULED            |1639        |0.0      |110333 |2024-11-26 23:33:47|2523_0_1|1|1|2330_GY0RX     |2024-11-26|test      |\n",
            "|7      |1_1404-11                     |STOPPED_AT    |41|1168 |38.72427 |1107   |-9.234712|1107_0_1  |1107_0  |SCHEDULED            |1499        |0.2777778|120033 |2024-11-26 23:34:00|1107_0_1_2300_2329_0_1_1V0AN|2024-11-26|test      |\n",
            "|62     |20241126-64010069-121740234560|IN_TRANSIT_TO |44|12533|38.685253|4600   |-8.948968|4600_1_2  |4600_1  |SCHEDULED            |121740234560|11.388889|100178 |2024-11-26 23:33:58|4600_1_2|2600|2300_24UH5    |2024-11-26|test      |\n",
            "|14     |UNAVAILABLE_BLOCK_ID          |IN_TRANSIT_TO |42|1008 |38.810566|2740   |-9.15034 |2740_2_2  |2740_2  |SCHEDULED            |42853       |27.777779|082308 |2024-11-26 23:33:20|2740_2_2|120|1|2325_GY0RX   |2024-11-26|test      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Loading data to /content/lake/silver/vehicles...\n",
            "Data successfully loaded to /content/lake/silver/vehicles\n",
            "ETL program completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------"
      ],
      "metadata": {
        "id": "bofPvjHa1Ozd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the directory paths\n",
        "os.makedirs('/content/lake/silver/vehicles', exist_ok=True)\n",
        "os.makedirs('/content/lake/silver/lines', exist_ok=True)\n",
        "os.makedirs('/content/lake/silver/municipalities', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "TXSu4FWm55HB"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Cleansing Process\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Paths for the Bronze layer\n",
        "vehicles_path = '/content/lake/bronze/vehicles'\n",
        "lines_path = '/content/lake/bronze/lines'\n",
        "municipalities_path = '/content/lake/bronze/municipalities'\n",
        "\n",
        "# Read data from the Bronze layer\n",
        "vehicles_df = spark.read.parquet(vehicles_path)\n",
        "lines_df = spark.read.parquet(lines_path)\n",
        "municipalities_df = spark.read.parquet(municipalities_path)\n"
      ],
      "metadata": {
        "id": "nWgi4mgR6kjj"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Cleansing Process\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Paths for the Bronze layer\n",
        "vehicles_path = '/content/lake/bronze/vehicles'\n",
        "lines_path = '/content/lake/bronze/lines'\n",
        "municipalities_path = '/content/lake/bronze/municipalities'\n",
        "\n",
        "# Read data from the Bronze layer\n",
        "vehicles_df = spark.read.parquet(vehicles_path)\n",
        "lines_df = spark.read.parquet(lines_path)\n",
        "municipalities_df = spark.read.parquet(municipalities_path)\n"
      ],
      "metadata": {
        "id": "AtYK3Ay86mmV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "vehicles_df = vehicles_df.withColumnRenamed(\"lat\", \"latitude\").withColumnRenamed(\"lon\", \"longitude\")\n",
        "\n",
        "# Remove duplicates\n",
        "vehicles_df = vehicles_df.dropDuplicates()\n",
        "\n",
        "# Remove rows with null CURRENT_STATUS\n",
        "vehicles_df = vehicles_df.filter(vehicles_df[\"CURRENT_STATUS\"].isNotNull())\n",
        "\n",
        "# Remove any corrupted records (e.g., rows with null or malformed data)\n",
        "# Assuming all columns should be non-null for simplicity\n",
        "vehicles_df = vehicles_df.dropna()\n"
      ],
      "metadata": {
        "id": "_rmDYOMq6ogs"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "lines_df = lines_df.dropDuplicates()\n",
        "\n",
        "# Remove rows with null LONG_NAME\n",
        "lines_df = lines_df.filter(lines_df[\"LONG_NAME\"].isNotNull())\n",
        "\n",
        "# Remove any corrupted records\n",
        "lines_df = lines_df.dropna()\n"
      ],
      "metadata": {
        "id": "KbUSbBVt6rNI"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "municipalities_df = municipalities_df.dropDuplicates()\n",
        "\n",
        "# Remove rows where NAME or DISTRICT_NAME is null\n",
        "municipalities_df = municipalities_df.filter(\n",
        "    (municipalities_df[\"NAME\"].isNotNull()) &\n",
        "    (municipalities_df[\"DISTRICT_NAME\"].isNotNull())\n",
        ")\n",
        "\n",
        "# Remove any corrupted records\n",
        "municipalities_df = municipalities_df.dropna()\n"
      ],
      "metadata": {
        "id": "-PCevZQu6tLV"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write transformed data to the Silver layer\n",
        "vehicles_path_silver = '/content/lake/silver/vehicles'\n",
        "lines_path_silver = '/content/lake/silver/lines'\n",
        "municipalities_path_silver = '/content/lake/silver/municipalities'\n",
        "\n",
        "# Write vehicles data partitioned by 'date'\n",
        "\n",
        "vehicles_df.write.partitionBy(\"date\").mode(\"overwrite\").parquet(vehicles_path_silver)\n",
        "\n",
        "\n",
        "# Write lines data\n",
        "lines_df.write.mode(\"overwrite\").parquet(lines_path_silver)\n",
        "\n",
        "# Write municipalities data\n",
        "municipalities_df.write.mode(\"overwrite\").parquet(municipalities_path_silver)\n"
      ],
      "metadata": {
        "id": "0ZfYn08-6vLX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from the Silver layer\n",
        "vehicles_silver_df = spark.read.parquet('/content/lake/silver/vehicles')\n",
        "lines_silver_df = spark.read.parquet('/content/lake/silver/lines')\n",
        "municipalities_silver_df = spark.read.parquet('/content/lake/silver/municipalities')\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "print(\"Vehicles Data:\")\n",
        "vehicles_silver_df.show(5)\n",
        "\n",
        "print(\"\\nLines Data:\")\n",
        "lines_silver_df.show(5)\n",
        "\n",
        "print(\"\\nMunicipalities Data:\")\n",
        "municipalities_silver_df.show(5)\n"
      ],
      "metadata": {
        "id": "QIG5u2oV6xM0",
        "outputId": "37710e7d-0725-48cf-a4ea-c937807eab11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vehicles Data:\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+----------+\n",
            "|bearing|            block_id|current_status|      id| latitude|line_id|longitude|pattern_id|route_id|schedule_relationship|    shift_id|    speed|stop_id|          timestamp|             trip_id|      date|\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+----------+\n",
            "|      0|           1_1019-11| IN_TRANSIT_TO| 41|1251|38.800488|   1517|-9.233361|  1517_0_1|  1517_0|            SCHEDULED|        1134|      0.0| 172169|2024-11-26 23:33:36|1517_0_1_2330_235...|2024-11-26|\n",
            "|     20|             1185-11|   INCOMING_AT| 42|2370|  38.9547|   2328| -8.98699|  2328_0_1|  2328_0|            SCHEDULED|        1279| 6.111111| 180765|2024-11-26 23:33:46|2328_0_1|1|1|2300...|2024-11-26|\n",
            "|     45|       ESC_DU_EU2077|   INCOMING_AT|  43|740|38.670692|   3525|-9.161458|  3525_0_2|  3525_0|            SCHEDULED|      EU2212|10.555555| 020101|2024-11-26 23:33:57|3525_0_2_2300_232...|2024-11-26|\n",
            "|      0|             1027-11|    STOPPED_AT| 42|2332|38.831066|   2708|-9.128245|  2708_0_1|  2708_0|            SCHEDULED|        1212|      0.0| 071335|2024-11-26 23:32:50|2708_0_1|1|1|2340...|2024-11-26|\n",
            "|     78|20241126-64010006...| IN_TRANSIT_TO|44|12657|38.652992|   4701|-9.025788|  4701_0_2|  4701_0|            SCHEDULED|123550234560|6.6666665| 090011|2024-11-26 23:33:51|4701_0_2|2600|233...|2024-11-26|\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Lines Data:\n",
            "+-------+----------+----+--------------------+--------------------+------------------+--------------------+--------+----------+----------+\n",
            "|  color|facilities|  id|          localities|           long_name|    municipalities|            patterns|  routes|short_name|text_color|\n",
            "+-------+----------+----+--------------------+--------------------+------------------+--------------------+--------+----------+----------+\n",
            "|#C61D23|        []|2115|             [Mafra]|Codeçal (Tapada N...|            [1109]|[2115_0_1, 2115_0_2]|[2115_0]|      2115|   #FFFFFF|\n",
            "|#C61D23|        []|2532|[Alverca, Vila Fr...|Alverca(Est) - Lo...|      [1114, 1107]|[2532_0_1, 2532_0_2]|[2532_0]|      2532|   #FFFFFF|\n",
            "|#C61D23|        []|3119|[Pinhal de Cima, ...|Pinhal Conde Cunh...|            [1510]|[3119_0_1, 3119_0_2]|[3119_0]|      3119|   #FFFFFF|\n",
            "|#C61D23|        []|3535|[Cacilhas, Cova d...|Cacilhas (Termina...|[1503, 1510, 1511]|[3535_0_1, 3535_0_2]|[3535_0]|      3535|   #FFFFFF|\n",
            "|#C61D23|        []|3545|[Corroios, Sta. M...|Corroios (Estação...|      [1510, 1511]|[3545_0_1, 3545_0_2]|[3545_0]|      3545|   #FFFFFF|\n",
            "+-------+----------+----+--------------------+--------------------+------------------+--------------------+--------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Municipalities Data:\n",
            "+----+-------------------+-----------+-------------+------+---------+-----------+--------------+\n",
            "|  id|               name|district_id|district_name|prefix|region_id|region_name|ingestion_date|\n",
            "+----+-------------------+-----------+-------------+------+---------+-----------+--------------+\n",
            "|1115|            Amadora|         11|       Lisboa|    03|    PT170|        AML|    2024-11-26|\n",
            "|1109|              Mafra|         11|       Lisboa|    08|    PT170|        AML|    2024-11-26|\n",
            "|1105|            Cascais|         11|       Lisboa|    05|    PT170|        AML|    2024-11-26|\n",
            "|1506|              Moita|         15|      Setúbal|    09|    PT170|        AML|    2024-11-26|\n",
            "|1114|Vila Franca de Xira|         11|       Lisboa|    18|    PT170|        AML|    2024-11-26|\n",
            "+----+-------------------+-----------+-------------+------+---------+-----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------"
      ],
      "metadata": {
        "id": "2R72ILTZ7QME"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ly7xAF0s9e8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}