{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joanadecaa1/data_processing/blob/main/spark/examples/03-sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfU2X4eaqMSC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucprosa/dataeng-basic-course/blob/main/spark/examples/03-sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# SQL\n",
        "- TempView\n",
        "- GlobalTempView\n",
        "- SQL\n",
        "- Catalog (saveAsTable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "e6d6bf32-ccd7-4c0e-b039-43d275a3b555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Spark Course').config('spark.ui.port', '4050').getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(\"c1\", \"v1\"), (\"c2\", \"v2\"), (\"c3\", \"v3\")]\n",
        "rdd = sc.parallelize(lst)\n",
        "df = rdd.toDF([\"col\", \"value\"])"
      ],
      "metadata": {
        "id": "xI5azn86QE5K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KosbhJyJqMSI",
        "outputId": "4f72a10b-8f9d-46b2-cad0-4df3e14cd1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "|col|value|\n",
            "+---+-----+\n",
            "| c1|   v1|\n",
            "| c2|   v2|\n",
            "| c3|   v3|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TempVIews - Session level\n",
        "df.createOrReplaceTempView(\"my_table\")\n",
        "spark.sql(\"select * from my_table\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tkqjl78sqMSI",
        "outputId": "379a8301-3e06-43bf-ea55-00a100cad34a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "|col|value|\n",
            "+---+-----+\n",
            "| c1|   v1|\n",
            "| c2|   v2|\n",
            "| c3|   v3|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GlobalTempViews - Spark application level - global_temp database\n",
        "df.createOrReplaceGlobalTempView(\"my_table2\")\n",
        "spark.sql(\"select * from globaL_temp.my_table2\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk0SIo0nqRwL",
        "outputId": "f3d8b5c6-e75c-4524-93df-c201dbdcd332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "|     test|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# interating with catalog\n",
        "spark.sql(\"create schema test\")\n",
        "spark.sql(\"show databases\").show()  #default vai sempre existir porque é o df padrão que é criado automáticamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dSbgHD32quHR"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame([(\"c1\", \"v1\"), (\"c2\", \"v2\")], schema=[\"col\", \"value\"])\n",
        "df.write.saveAsTable(\"test.my_table\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# listing tables from test\n",
        "spark.sql(\"show tables from test\").show() #vai aparecer as temp views como tabelas"
      ],
      "metadata": {
        "id": "YVFyShr2ZD5j",
        "outputId": "a4acbe42-449f-4f19-eb2f-eaca3ef60f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----------+\n",
            "|namespace|tableName|isTemporary|\n",
            "+---------+---------+-----------+\n",
            "|     test| my_table|      false|\n",
            "|         | my_table|       true|\n",
            "+---------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from test.my_table\").show()"
      ],
      "metadata": {
        "id": "ISx7T8ddZVjl",
        "outputId": "8df8714e-f453-4cca-b6dc-f45fc945c3a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "|col|value|\n",
            "+---+-----+\n",
            "| c1|   v1|\n",
            "| c2|   v2|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}